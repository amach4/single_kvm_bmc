#
# (c) Copyright 2015-2016 Hewlett Packard Enterprise Development LP
# (c) Copyright 2018 SUSE LLC
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
#
---
  product:
    version: 2

  disk-models:
  - name: CONTROLLER-1TB-DISKS

    # This example is based on using a single 1TB disk for a volume
    # group that contains all file systems on a controller with 64GB
    # of memory.
    #
    # Additional disks can be added to the 'physical-volumes' section.
    #
    #

    volume-groups:
      - name: ardana-vg
        physical-volumes:

          # NOTE: 'sda_root' is a templated value. This value is checked in
          # os-config and replaced by the partition actually used on sda
          #e.g. sda1 or sda5
          - /dev/sda_root

          # Add any additional disks for the volume group here
          # -/dev/sdx
          # -/dev/sdy

        logical-volumes:
          # The policy is not to consume 100% of the space of each volume group.
          # At least 5% should be left free for snapshots. This example leaves 18%
          # free to allow for some flexibility.

          - name: root
            size: 6%
            fstype: ext4
            mount: /

          # Reserved space for kernel crash dumps
          # Should evaluate to a value that is slightly larger than
          # the memory size of your server
          - name: crash
            size: 6%
            mount: /var/crash
            fstype: ext4
            mkfs-opts: -O large_file

          # Local Log files.  Depending on your retention policy
          # log files can require significant disc space
          - name: log
            size: 15%
            mount: /var/log
            fstype: ext4
            mkfs-opts: -O large_file

          # Mysql Database.  All persistent state from OpenStack services
          # is saved here.  Although the individual objects are small the
          # accumulated data can grow over time
          - name: mysql
            size: 6%
            mount: /var/lib/mysql
            fstype: ext4
            mkfs-opts: -O large_file
            consumer:
              name: mysql

          # Rabbitmq works mostly in memory, but needs to be able to persist
          # messages to disc under high load. This area should evaluate to a value
          # that is slightly larger than the memory size of your server
          - name: rabbitmq
            size: 7%
            mount: /var/lib/rabbitmq
            fstype: ext4
            mkfs-opts: -O large_file
            consumer:
              name: rabbitmq
              rabbitmq_env: home

          # Database storage for event monitoring and metering data (Monasca).
          - name: cassandra_db
            size: 19%
            mount: /var/cassandra/data
            fstype: ext4
            mkfs-opts: -O large_file
            consumer:
              name: cassandra

          - name: cassandra_log
            size: 1%
            mount: /var/cassandra/commitlog
            fstype: ext4
            mkfs-opts: -O large_file
            consumer:
              name: cassandra

          # Messaging system for monitoring and logging.
          - name: kafka
            size: 7%
            mount: /var/kafka
            fstype: ext4
            mkfs-opts: -O large_file
            consumer:
              name: kafka

          # Data storage for centralized logging. This holds log entries from all
          # servers in the cloud and hence can require a lot of disk space.
          - name: elasticsearch
            size: 13%
            mount: /var/lib/elasticsearch
            fstype: ext4

          # Zookeeper is used to provide cluster co-ordination in the monitoring
          # system.  Although not a high user of disc space we have seen issues
          # with zookeeper snapshots filling up filesystems so we keep it in its
          # own space for stability.
          - name: zookeeper
            size: 1%
            mount: /var/lib/zookeeper
            fstype: ext4

        consumer:
           name: os

    # Cinder: cinder volume needs temporary local filesystem space to convert
    # images to raw when creating bootable volumes. Using a separate volume
    # will both ringfence this space and avoid filling /
    # The size should represent the raw size of the largest image times
    # the number of concurrent bootable volume creations.
    # The logical volume can be part of an existing volume group or a
    # dedicated volume group.
    #  - name: cinder-vg
    #    physical-volumes:
    #      - /dev/sdx
    #    logical-volumes:
    #     - name: cinder_image
    #       size: 5%
    #       mount: /var/lib/cinder
    #       fstype: ext4

    #  Glance cache: if a logical volume with consumer usage 'glance-cache'
    #  is defined Glance caching will be enabled. The logical volume can be
    #  part of an existing volume group or a dedicated volume group.
    #  - name: glance-vg
    #    physical-volumes:
    #      - /dev/sdx
    #    logical-volumes:
    #     - name: glance-cache
    #       size: 95%
    #       mount: /var/lib/glance/cache
    #       fstype: ext4
    #       mkfs-opts: -O large_file
    #       consumer:
    #         name: glance-api
    #         usage: glance-cache

    # Audit: Audit logs can consume significant disc space.  If you
    # are enabling audit then it is recommended that you use a dedicated
    # disc.
    #  - name: audit-vg
    #    physical-volumes:
    #      - /dev/sdz
    #    logical-volumes:
    #      - name: audit
    #        size: 95%
    #        mount: /var/audit
    #        fstype: ext4
    #        mkfs-opts: -O large_file

    # Additional disk group defined for Swift
    device-groups:
      - name: swiftobj
        devices:
          - name: /dev/sdb
          - name: /dev/sdc
          # Add any additional disks for swift here
          # -name: /dev/sdd
          # -name: /dev/sde
        consumer:
          name: swift
          attrs:
            rings:
              - account
              - container
              - object-0
