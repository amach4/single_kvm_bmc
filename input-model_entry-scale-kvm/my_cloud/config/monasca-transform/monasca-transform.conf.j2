{#
#
# (c) Copyright 2016-2017 Hewlett Packard Enterprise Development LP
# (c) Copyright 2017-2018 SUSE LLC
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
#
#}
[DEFAULTS]

[repositories]
offsets = monasca_transform.mysql_offset_specs:MySQLOffsetSpecs
data_driven_specs = monasca_transform.data_driven_specs.mysql_data_driven_specs_repo:MySQLDataDrivenSpecsRepo
offsets_max_revisions = 10

[database]
server_type = {{ mon_tra_jdbc_server_type }}
host = {{ mon_tra_mysql_target_host }}
database_name = monasca_transform
username = {{ mon_tra_mysql_user }}
password = {{ mon_tra_mysql_password }}
use_ssl = {{ mon_tra_db_use_ssl }}
ca_file = {{ mon_tra_ca_file }}

[messaging]
adapter = monasca_transform.messaging.adapter:KafkaMessageAdapter
topic = metrics
brokers = {{ mon_tra_kafka_brokers }}
publish_kafka_project_id = {{ mon_tra_admin_project_id }}
publish_region = {{ mon_tra_region }}
adapter_pre_hourly = monasca_transform.messaging.adapter:KafkaMessageAdapterPreHourly
topic_pre_hourly = metrics_pre_hourly

[stage_processors]
pre_hourly_processor_enabled = True

[pre_hourly_processor]
late_metric_slack_time = 600
enable_instance_usage_df_cache = True
instance_usage_df_cache_storage_level = MEMORY_ONLY_SER_2
enable_batch_time_filtering = True
data_provider=monasca_transform.processor.pre_hourly_processor:PreHourlyProcessorDataProvider

#
# Configurable values for the monasca-transform service
#
[service]

# The address of the mechanism being used for election coordination
coordinator_address = kazoo://{{ mon_tra_zookeeper_hosts }}

# The name of the coordination/election group
coordinator_group = monasca-transform

# How long the candidate should sleep between election result queries
election_polling_frequency = 15

# Whether debug-level log entries should be included in the application
# log.  If this setting is false, info-level will be used for logging.
enable_debug_log_entries = false

# The path for the monasca-transform Spark driver
spark_driver = {{ mon_tra_service_dir }}/driver.py

# the location for the transform-service log
service_log_path={{ mon_tra_service_log_dir }}

# the filename for the transform-service log
service_log_filename={{ mon_tra_service_log_filename }}

# Whether Spark event logging should be enabled (true/false)
spark_event_logging_enabled = {{ mon_tra_event_logging_enabled }}

# A list of jars which Spark should use
{% if deployer_media_legacy_layout|bool %}
spark_jars_list = {{ mon_tra_spark_home }}/lib/spark-streaming-kafka.jar,{{ mon_tra_spark_home }}/lib/scala-library-2.10.1.jar,{{ mon_tra_spark_home }}/lib/kafka_2.10-0.8.1.1.jar,{{ mon_tra_spark_home }}/lib/metrics-core-2.2.0.jar,{{ mon_tra_spark_home }}/lib/drizzle-jdbc-1.3.jar
{% else %}
spark_jars_list = {{ mon_tra_spark_home }}/lib/spark-streaming-kafka.jar,{{ mon_tra_spark_home }}/lib/scala-library-2.10.4.jar,{{ mon_tra_spark_home }}/lib/kafka_2.10-0.8.2.1.jar,{{ mon_tra_spark_home }}/lib/metrics-core-2.2.0.jar,{{ mon_tra_spark_home }}/lib/mysql-connector-java.jar
{% endif %}

# A list of where the Spark master(s) should run
spark_master_list = spark://{{ mon_tra_spark_masters }}

# spark_home for the environment
spark_home = {{ mon_tra_spark_home }}

# Python files for Spark to use
spark_python_files = {{ mon_tra_service_dir }}/{{ mon_tra_zip_filename }}

# How often the stream should be read (in seconds)
stream_interval = {{ mon_tra_stream_interval }}

# The working directory for monasca-transform
work_dir = {{ mon_tra_service_run_dir }}

# enable caching of record store df
enable_record_store_df_cache = True

# set spark storage level for record store df cache
record_store_df_cache_storage_level = MEMORY_ONLY_SER_2
